const { onDocumentCreated, onDocumentUpdated } = require("firebase-functions/v2/firestore");
const { onCall } = require("firebase-functions/v2/https");
const { initializeApp } = require("firebase-admin/app");
const { getFirestore } = require("firebase-admin/firestore");
const vision = require("@google-cloud/vision");
const { GoogleGenerativeAI } = require("@google/generative-ai");
const axios = require("axios");

const app = initializeApp();
const db = getFirestore(app);

// Initialize clients
// Note: These require Google Cloud credentials/env vars to work in production
const visionClient = new vision.ImageAnnotatorClient();

// Gemini API Key from environment variable
// You need to set this via: firebase functions:config:set gemini.key="YOUR_KEY"
// Or use defineString for v2 functions
const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "YOUR_GEMINI_API_KEY_HERE";
const GOOGLE_MAPS_API_KEY = process.env.GOOGLE_MAPS_API_KEY || "YOUR_MAPS_API_KEY_HERE";

exports.analyzeIssueRequest = onDocumentCreated({
    document: "issues/{issueId}",
    database: "default"
}, async (event) => {
    const snapshot = event.data;
    if (!snapshot) {
        return;
    }

    const data = snapshot.data();
    const issueId = event.params.issueId;

    // Prevent infinite loops or re-runs if already analyzed
    if (data.status !== 'open' || data.aiAnalysis?.verified) {
        return;
    }

    console.log(`Analyzing issue ${issueId}: ${data.imageUrl}`);

    try {
        const changes = {};

        // 1. Vision API - Label Detection
        // For Hackathon demo: we might skip this if credentials aren't set, 
        // but the logic is here.
        let labels = [];
        try {
            // NOTE: gCloud Vision Client expects valid credentials on the backend environment.
            // If running locally without credentials, this might fail.
            const [result] = await visionClient.labelDetection(data.imageUrl);
            labels = result.labelAnnotations.map(label => label.description);
            console.log("Vision Labels:", labels);
        } catch (err) {
            console.warn("Vision API failed (likely no creds):", err.message);
            // Fallback/Mock for demo if API fails
            labels = ["road", "asphalt", "infrastructure", "pothole"];
        }

        // 2. Verification Logic
        // Simple check: Does the user's manual label appear in broadly matched tags?
        const issueType = (data.manualLabel || "").toLowerCase();
        const isVerified = labels.some(l =>
            l.toLowerCase().includes(issueType) ||
            issueType.includes(l.toLowerCase()) ||
            // Broad categories
            (issueType === 'pothole' && ['road', 'asphalt', 'tar', 'street'].includes(l.toLowerCase())) ||
            (issueType === 'garbage' && ['waste', 'trash', 'litter', 'plastic'].includes(l.toLowerCase()))
        );

        changes.aiAnalysis = {
            detectedLabels: labels,
            verified: isVerified,
            confidenceScore: isVerified ? 0.95 : 0.4
        };

        if (!isVerified) {
            changes.status = 'flagged'; // Flag for admin review
        } else {
            changes.status = 'verified';
        }

        // 3. Gemini API - Summarization
        try {
            if (GEMINI_API_KEY !== "YOUR_GEMINI_API_KEY_HERE") {
                const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
                const model = genAI.getGenerativeModel({ model: "gemini-pro" });

                const prompt = `A citizen reported a "${data.manualLabel}" at location ${data.location?.address}. 
                        Vision API detected: ${labels.join(", ")}. 
                        Write a 1-sentence urgent summary for a city official.`;

                const result = await model.generateContent(prompt);
                const response = await result.response;
                changes.aiAnalysis.summary = response.text();
            } else {
                changes.aiAnalysis.summary = `AI Summary: Verified ${data.manualLabel} report based on visual evidence of ${labels.slice(0, 3).join(", ")}.`;
            }
        } catch (err) {
            console.warn("Gemini API failed:", err.message);
            changes.aiAnalysis.summary = "AI Summary unavailable.";
        }

        // 4. Reverse Geocoding (if location is raw lat/long)
        // Front-end already tries to provide address, but we can double check here using Google Maps API
        // (Skipped for brevity, relying on frontend data for now)

        // Write back to Firestore
        await snapshot.ref.update(changes);
        console.log(`Updated issue ${issueId} with Analysis`);

    } catch (error) {
        console.error("Error in analyzeIssueRequest:", error);
    }
});

exports.onIssueStatusChange = onDocumentUpdated({
    document: "issues/{issueId}",
    database: "default"
}, async (event) => {
    const newData = event.data.after.data();
    const previousData = event.data.before.data();

    // Check if status has changed
    if (newData.status === previousData.status) return;

    const issueId = event.params.issueId;
    const userId = newData.userId;

    console.log(`Issue ${issueId} status changed from ${previousData.status} to ${newData.status}`)

    // Create Notification content based on new status
    let title = '';
    let message = '';
    let type = 'info';

    switch (newData.status) {
        case 'verified':
            title = 'Report Verified';
            message = `Your report for ${newData.manualLabel || 'issue'} has been verified by our AI. You earned 50 points!`;
            type = 'success';
            break;
        case 'resolved':
            title = 'Issue Resolved! ðŸŽ‰';
            message = `Great news! The ${newData.manualLabel || 'issue'} in ${newData.location?.address} has been fixed.`;
            type = 'success';
            break;
        case 'flagged':
            title = 'Report Flagged';
            message = `Your report was flagged for further review. Our team will look into it.`;
            type = 'alert';
            break;
        case 'in-progress':
            title = 'Work Started';
            message = `Maintenance crew is currently working on your report.`;
            type = 'info';
            break;
        default:
            return;
    }

    try {
        await db.collection('notifications').add({
            userId: userId || 'anonymous',
            issueId: issueId,
            type: type,
            title: title,
            message: message,
            read: false,
            createdAt: new Date(),
        });
        console.log(`Notification created for ${issueId}`);
    } catch (error) {
        console.error("Error creating notification:", error);
    }
});

// Callable function: Analyze image via Vision API
// Frontend can call this for immediate analysis feedback
exports.analyzeImage = onCall(async (request) => {
    const { imageUrl, storagePath, bucket } = request.data || {};

    if (!imageUrl && !(storagePath && bucket)) {
        throw new Error("imageUrl or (storagePath + bucket) is required");
    }

    let labels = [];
    try {
        // Prefer GCS path if provided; else use public download URL
        const imageSource = storagePath && bucket
            ? { image: { source: { imageUri: `gs://${bucket}/${storagePath}` } } }
            : imageUrl;

        const [result] = await visionClient.labelDetection(imageSource);
        labels = result.labelAnnotations || [];
    } catch (err) {
        console.warn("Callable Vision API failed:", err.message);
        // Provide fallback to keep UI responsive
        labels = [
            { description: "road", score: 0.95 },
            { description: "asphalt", score: 0.92 },
            { description: "pothole", score: 0.88 },
        ];
    }

    // Basic mapping
    const lower = labels.map(l => (l.description || "").toLowerCase());
    let detectedIssueType = "other";
    if (lower.some(d => d.includes("pothole") || d.includes("crack"))) detectedIssueType = "pothole";
    else if (lower.some(d => d.includes("trash") || d.includes("garbage") || d.includes("litter"))) detectedIssueType = "garbage";
    else if (lower.some(d => d.includes("tree") || d.includes("branch"))) detectedIssueType = "tree";
    else if (lower.some(d => d.includes("water") || d.includes("flood"))) detectedIssueType = "flooding";

    return {
        labels,
        detectedIssueType,
        confidence: 0.85,
    };
});

// Callable function: Generate description via Gemini
exports.generateDescription = onCall(async (request) => {
    const { imageUrl, visionResults } = request.data || {};

    let description = "";
    try {
        if (GEMINI_API_KEY && GEMINI_API_KEY !== "YOUR_GEMINI_API_KEY_HERE") {
            const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
            const model = genAI.getGenerativeModel({ model: "gemini-pro" });
            const prompt = `A citizen reported an infrastructure issue. Detected labels: ${
                (visionResults?.labels || []).map(l => l.description).join(", ")
            }. Generate a concise municipal report description.`;
            const result = await model.generateContent(prompt);
            description = (await result.response).text();
        } else {
            // Fallback text if Gemini key is not set
            const issueType = visionResults?.detectedIssueType || "other";
            description = `AI summary for ${issueType}: based on visual cues ${
                (visionResults?.labels || []).slice(0,3).map(l => l.description).join(", ")
            }.`;
        }
    } catch (err) {
        console.warn("Callable Gemini API failed:", err.message);
        description = "AI description unavailable.";
    }

    return {
        description,
        suggestedPriority: ["pothole", "flooding", "road-damage", "tree"].includes(visionResults?.detectedIssueType)
            ? "high"
            : "medium",
        confidence: 0.87,
        keywords: (visionResults?.labels || []).slice(0, 3).map(l => l.description),
    };
});
